{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8回：モデルの改善\n",
    "* 前回は機械学習（決定木とランダムフォレスト）で予測モデルを作成し、精度評価を行いランダムフォレストのほうが精度が良いことを確認しました。\n",
    "* 実際に機械学習を活用する場合には1回でいきなり良い精度になることは少なく、試行錯誤をしながら精度を上げていくことがほとんどです。\n",
    "* 今回はランダムフォレストを用いて、精度向上の取り組みとして以下の2テーマを行います。\n",
    "    * ハイパーパラメータチューニング\n",
    "    * 新たな特徴量の作成（予測に影響しそうな列を新たに作成）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. データ読み込み\n",
    "* まずはデータを読み込みましょう。\n",
    "* 予測モデル作成用に整形したデータ（data_ml.csv）を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd             # 表形式のデータ操作ライブラリ\n",
    "import matplotlib.pyplot as plt # グラフ描画ライブラリ\n",
    "import seaborn as sns           # グラフ描画ライブラリ\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier      # 決定木による分類のためのライブラリ\n",
    "from sklearn.ensemble import RandomForestClassifier  # ランダムフォレストによる分類のためのライブラリ\n",
    "\n",
    "from sklearn.metrics import roc_auc_score     # AUC値を算出するライブラリ\n",
    "from sklearn.metrics import roc_curve         # ROC曲線を描画するためのライブラリ\n",
    "from sklearn.metrics import accuracy_score    # 正解率を算出するライブラリ\n",
    "from sklearn.metrics import confusion_matrix  # 混同行列を作成するライブラリ\n",
    "\n",
    "from sklearn.model_selection import train_test_split # データを学習用と検証用に分割するライブラリ\n",
    "from sklearn.model_selection import GridSearchCV     # グリッドサーチによるパラメータチューニングを実施するライブラリ\n",
    "\n",
    "random_state = 1 # 乱数固定\n",
    "sns.set() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 警告（warning）を表示させない\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('データのサイズ：', data.shape) # データサイズ確認\n",
    "display(data.head()) # データが正しく読み込めたことを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを説明変数と目的変数に分割し、さらに学習用データと検証用データに分割\n",
    "X = data.drop(['y'],axis=1)\n",
    "y = data.y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=random_state) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ランダムフォレストの予測精度の再確認\n",
    "* 前回の演習でも実施しましたが、ランダムフォレストの予測精度を再確認してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. 評価指標の表示を関数にまとめる\n",
    "* 同じ処理を何度も実施する場合は、関数としてまとめておくと便利です。\n",
    "* 関数を呼び出すことで、簡単に処理を実行できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_eval(model, X_test, y_test) :\n",
    "    ## この関数では、学習済みモデル、検証用説明変数、検証用目的変数をもとに ##\n",
    "    ## 正解率、AUC、ROC曲線、特徴量重要度を表示する関数です                 ##\n",
    "    \n",
    "    # 正解率を確認\n",
    "    y_pred = model.predict(X_test)\n",
    "    ac = accuracy_score(y_test, y_pred)\n",
    "    print('正解率：{:.3f}'.format(ac))    \n",
    "    \n",
    "    # AUCを確認\n",
    "    y_prob = model.predict_proba(X_test) # 0,1ではなく予測確率を出力\n",
    "    auc = roc_auc_score(y_test,y_prob[:,1])\n",
    "    print('AUC：{:.3f}'.format(auc))    \n",
    "    \n",
    "    # ROC曲線描画\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob[:,1])\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1],[0,1],color=\"gray\",linestyle=\"dotted\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    \n",
    "    # 特徴量重要度を確認\n",
    "    feature_importances = pd.DataFrame(model.feature_importances_,\n",
    "                                  index = X_test.columns,\n",
    "                                  columns=[\"importance\"]).sort_values(\"importance\",ascending=False)\n",
    "    feature_importances.head(20).plot.bar(figsize=(12,4), fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. ランダムフォレストの精度確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state = random_state)  # この時点では未学習（常に同じ結果が出るようにrandom_stateで乱数固定）\n",
    "forest.fit(X_train, y_train)   \n",
    "\n",
    "pred_and_eval(forest, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 精度改善その1：パラメータチューニング\n",
    "\n",
    "* まずはランダムフォレストのパラメータを調整して精度向上できるか確認しましょう。\n",
    "* 今回は以下の3つのパラメータについて順番に探索します。\n",
    "    * 「木の深さ」max_depth\n",
    "    * 「決定木の数」n_estimators\n",
    "    * 「分岐に必要なデータ数」min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. max_depthの探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_list = [5,10,15,20,25,30]\n",
    "aucs =[]\n",
    "for depth in tqdm(depth_list): # 5, 10, ... とmax_depthを変えたときの精度を繰り返し確認\n",
    "    rf = RandomForestClassifier(max_depth= depth , n_estimators=100, random_state=random_state) # この時点では未学習\n",
    "    rf.fit(X_train, y_train)                  # 学習\n",
    "    y_prob = rf.predict_proba(X_test)         # 0,1ではなく予測確率を出力\n",
    "    auc = roc_auc_score(y_test,y_prob[:,1])   # AUCスコアを算出\n",
    "    aucs.append(auc)                          # 算出したAUCを記録\n",
    "    \n",
    "plt.plot(depth_list,aucs) # max_depthごとのAUCを折れ線グラフで描画"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. n_estimatorsの探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = [5,10,20,30,50,100,200,300]\n",
    "aucs =[]\n",
    "for param in tqdm(param_list):\n",
    "    rf = RandomForestClassifier(max_depth= 15 , n_estimators=param, random_state=random_state)\n",
    "    rf.fit(X_train, y_train) \n",
    "    y_prob = rf.predict_proba(X_test) # 0,1ではなく予測確率を出力\n",
    "    auc = roc_auc_score(y_test,y_prob[:,1])\n",
    "    aucs.append(auc)\n",
    "plt.plot(param_list,aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_samples_leafの探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = [1,2,3,4,5,7,10,20]\n",
    "aucs =[]\n",
    "for param in tqdm(param_list):\n",
    "    rf = RandomForestClassifier(max_depth= 15 , n_estimators=200, min_samples_leaf=param, random_state=random_state)\n",
    "    rf.fit(X_train, y_train) \n",
    "    y_prob = rf.predict_proba(X_test) # 0,1ではなく予測確率を出力\n",
    "    auc = roc_auc_score(y_test,y_prob[:,1])\n",
    "    aucs.append(auc)\n",
    "plt.plot(param_list,aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. 探索したパラメータで最終確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier(max_depth= 15, n_estimators=200, min_samples_leaf=3, random_state=random_state)\n",
    "rf = RandomForestClassifier(max_depth= 15, n_estimators=200, min_samples_leaf=3, random_state=random_state)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "pred_and_eval(rf, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 精度改善その2：特徴量作成\n",
    "* 機械学習ではデータから自動でパターンを学習して予測モデルを作成できますが、学習させるデータに人間の知見を加えることで、より良いモデルが作成できます。\n",
    "* 対象業界に詳しい人の知見を取り入れたり、第2回演習で実施したようなデータのグラフ化による仮設立案などから、新たな特徴量（列）を追加します。\n",
    "* 実際に、予測精度の向上を目指して予測に効果がありそうな特徴量（列）を追加してみましょう。\n",
    "* 今回は学習用データと検証用データを分割する前のデータでグラフ化しながら確認していますが、実際の業務で分析を行う際には、学習用データのみを使い仮設検討し、検証用データで精度検証を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. 曜日の追加\n",
    "* データの年月日がわかっているので、曜日を表す列を追加することができます。\n",
    "* 予測対象にもよりますが、「金曜日は居酒屋が混雑しやすい」など、曜日が売上や契約に関係するケースは多くあります。\n",
    "* 実際に曜日を表す列を追加してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### year, month, dayを組み合わせて年月日列（date列）を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date\"]= pd.to_datetime(data[\"year\"].astype(int).astype(str) + \"/\" + data[\"month\"].astype(str) + \"/\" + data[\"day\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('データのサイズ：', data.shape) # データサイズ確認\n",
    "display(data.head())                  # date列を作成できたことを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### date列をもとに曜日列を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['day_name'] = data['date'].dt.day_name()  # day_name で曜日を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('データのサイズ：', data.shape) # データサイズ確認\n",
    "display(data.head())                  # day_name列を追加できたことを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 曜日ごとに定期預金をした人としていない人の割合をグラフ化して確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'day_name'\n",
    "sns.set()               # グラフのデザインをSeabornライブラリのデフォルトスタイルに変更\n",
    "sns.set_context('talk') # グラフの字の大きさを調整\n",
    "\n",
    "# カテゴリ別にグラフ化するためにデータを加工\n",
    "count_data = (data.groupby(col_name)['y']   # 集計対象の列でグループ化\n",
    "              .value_counts(normalize=True) # 割合算出\n",
    "              .rename('percentage') \n",
    "              .reset_index())\n",
    "\n",
    "sns.catplot(x='y', y='percentage', col=col_name, kind='bar', data=count_data) # catplotで棒グラフを描画"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* グラフでは曜日による違いは少なそうに見えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 曜日列を数値に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies機能を使い、day_name 列のOne-Hotエンコーディングを行います。\n",
    "data = pd.get_dummies(data, columns = ['day_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 曜日を追加できたので、一時的に追加した年月日列を削除します\n",
    "data.drop(\"date\",axis=1,inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. データを学習用データと検証用データに分割し、精度検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['y'],axis=1)\n",
    "y = data.y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=random_state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth= 15, n_estimators=200, min_samples_leaf=3, random_state=random_state)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "pred_and_eval(rf, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 精度改善その3：新たなデータの追加（経済指標）\n",
    "* 手元にあるデータだけでは、特徴量作成などの工夫による精度向上にも限界があります。\n",
    "* そのような場合には、新しいデータを追加することで精度向上できる場合もあります。\n",
    "* 今回のテーマは定期預金の契約予測なので、新たに経済指標データを追加してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "economic = pd.read_csv(\"economic.csv\")\n",
    "economic['month'] = economic['month'].map( {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, \n",
    "                                'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12} ).astype(int)\n",
    "economic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 追加指数の説明\n",
    "* year          ：該当年\n",
    "* month         ：該当月\n",
    "* emp.var.rate  ：雇用者数の変動率\n",
    "* cons.price.idx：消費者物価指数\n",
    "* cons.conf.idx ：消費者信頼感指数\n",
    "* nr.employed   ：総雇用者数 \n",
    "* euribor3m     ：ユーロ圏での銀行間取引金利（３か月）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataとeconomicをyear列とmonth列が同じ所で結合する\n",
    "data_ext = pd.merge(data,economic, on=[\"year\",\"month\"])\n",
    "data_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_ext.drop(['y'],axis=1)\n",
    "y = data_ext.y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=random_state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth= 15, n_estimators=200, min_samples_leaf=3, random_state=random_state)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "pred_and_eval(rf, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
